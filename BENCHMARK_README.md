# GUIDE COMPLET DU BENCHMARK PARQUET vs HBASE

Ce guide explique comment exÃ©cuter le benchmark complet comparant les performances de Parquet et HBase avec Spark SQL.

## ğŸ“‹ PRÃ‰REQUIS

1. **Docker Desktop** installÃ© et en cours d'exÃ©cution
2. **Tous les services** dÃ©marrÃ©s via `docker-compose up -d`
3. **Fichier CSV** uploadÃ© sur HDFS

## ğŸš€ DÃ‰MARRAGE RAPIDE

### Option 1: Script automatique (recommandÃ©)

```bash
# Rendre le script exÃ©cutable
chmod +x run_full_benchmark.sh

# ExÃ©cuter le benchmark complet
./run_full_benchmark.sh
```

### Option 2: ExÃ©cution manuelle Ã©tape par Ã©tape

Suivez les Ã©tapes ci-dessous.

---

## ğŸ“ Ã‰TAPES DÃ‰TAILLÃ‰ES

### Ã‰TAPE 1: VÃ©rification des services

VÃ©rifiez que tous les services sont opÃ©rationnels:

```bash
bash scripts/verify_services.sh
```

Ou manuellement:

```bash
# VÃ©rifier Docker
docker ps

# VÃ©rifier HDFS
docker exec namenode hdfs dfs -ls /

# VÃ©rifier HBase
docker exec hbase-master bash -c "echo 'list' | hbase shell -n"

# VÃ©rifier Spark
docker exec spark-master-new jps
```

### Ã‰TAPE 2: Upload du CSV sur HDFS

Si le fichier CSV n'est pas dÃ©jÃ  sur HDFS:

```bash
bash scripts/upload_csv_to_hdfs.sh
```

Ou manuellement:

```bash
docker cp sample_sales.csv namenode:/tmp/
docker exec namenode hdfs dfs -mkdir -p /user/data
docker exec namenode hdfs dfs -put /tmp/sample_sales.csv /user/data/sample_sales.csv
```

### Ã‰TAPE 3: PrÃ©paration de HBase

CrÃ©ez la table HBase:

```bash
bash scripts/prepare_hbase.sh
```

Ou manuellement:

```bash
docker exec hbase-master bash -c "echo 'create \"sales\", \"cf\"' | hbase shell -n"
docker exec hbase-master bash -c "echo 'list' | hbase shell -n"
```

### Ã‰TAPE 4: Benchmark HBase

ExÃ©cutez le benchmark HBase:

```bash
# Copier les scripts dans le conteneur Spark
docker cp benchmark_hbase.py spark-master-new:/benchmark_hbase.py
docker cp benchmark_config.py spark-master-new:/benchmark_config.py

# ExÃ©cuter le benchmark
docker exec spark-master-new /opt/spark/bin/spark-submit \
    --master spark://spark-master-new:7077 \
    --packages org.apache.hbase:hbase-client:2.1.3,org.apache.hbase:hbase-common:2.1.3 \
    /benchmark_hbase.py
```

### Ã‰TAPE 5: Benchmark Parquet

ExÃ©cutez le benchmark Parquet:

```bash
# Copier les scripts dans le conteneur Spark
docker cp benchmark_parquet_complete.py spark-master-new:/benchmark_parquet_complete.py
docker cp benchmark_config.py spark-master-new:/benchmark_config.py

# ExÃ©cuter le benchmark
docker exec spark-master-new /opt/spark/bin/spark-submit \
    --master spark://spark-master-new:7077 \
    /benchmark_parquet_complete.py
```

### Ã‰TAPE 6: GÃ©nÃ©ration du tableau comparatif

GÃ©nÃ©rez le tableau comparatif final:

```bash
# Copier les scripts dans le conteneur Spark
docker cp generate_comparison.py spark-master-new:/generate_comparison.py
docker cp benchmark_config.py spark-master-new:/benchmark_config.py

# ExÃ©cuter la gÃ©nÃ©ration
docker exec spark-master-new /opt/spark/bin/spark-submit \
    --master spark://spark-master-new:7077 \
    /generate_comparison.py
```

---

## ğŸ“Š CONSULTATION DES RÃ‰SULTATS

### Via Spark SQL

```bash
docker exec -it spark-master-new /opt/spark/bin/spark-sql
```

Puis dans Spark SQL:

```sql
USE perf;

-- Voir les mÃ©triques HBase
SELECT * FROM hbase_metrics;

-- Voir les mÃ©triques Parquet
SELECT * FROM parquet_metrics;

-- Voir le tableau comparatif
SELECT * FROM comparison_results;
```

### Via fichiers locaux

Les rÃ©sultats sont Ã©galement disponibles dans:

- **CSV:** `benchmark_results/comparison_results.csv`
- **Rapport Markdown:** `benchmark_results/benchmark_report.md`

### Via HDFS

```bash
# Voir les fichiers Parquet
docker exec namenode hdfs dfs -ls /user/output/parquet_sample

# Voir la taille
docker exec namenode hdfs dfs -du -h /user/output/parquet_sample
```

---

## ğŸ”§ CONFIGURATION

Toutes les variables de configuration sont dans `benchmark_config.py`:

- Chemins HDFS
- Noms de tables HBase
- Noms de tables Hive
- Nombre d'itÃ©rations pour les benchmarks

Modifiez ce fichier selon vos besoins.

---

## ğŸ“ˆ MÃ‰TRIQUES MESURÃ‰ES

### Pour HBase:
- Temps de lecture CSV
- Temps d'Ã©criture (min/max/moyen)
- Temps de scan complet
- Temps de conversion en DataFrame
- Temps des requÃªtes Spark SQL (SELECT, FILTER, GROUP BY, COUNT)

### Pour Parquet:
- Temps de lecture CSV
- Temps d'Ã©criture (min/max/moyen)
- Temps de lecture
- Taille du dossier Parquet
- Compression utilisÃ©e
- Temps des requÃªtes Spark SQL (SELECT, FILTER, GROUP BY, COUNT, requÃªtes complexes)

### Comparaison:
- Speedup (ratio de performance)
- DiffÃ©rence de temps
- DiffÃ©rence en pourcentage

---

## ğŸ› DÃ‰PANNAGE

### ProblÃ¨me: HBase n'est pas accessible

```bash
# VÃ©rifier les logs
docker logs hbase-master
docker logs hbase-regionserver
docker logs zookeeper

# VÃ©rifier l'Ã©tat
docker exec hbase-master jps
docker exec hbase-regionserver jps
```

### ProblÃ¨me: Spark ne peut pas se connecter Ã  HDFS

```bash
# VÃ©rifier la configuration
docker exec spark-master-new cat /opt/hadoop/etc/hadoop/core-site.xml

# Tester la connexion
docker exec spark-master-new hdfs dfs -ls /
```

### ProblÃ¨me: Les tables Hive n'existent pas

```bash
# VÃ©rifier la connexion au metastore
docker logs hive-metastore

# VÃ©rifier PostgreSQL
docker exec hive-metastore-postgresql psql -U hiveuser -d metastore -c "\dt"
```

### ProblÃ¨me: Erreur de dÃ©pendances HBase dans Spark

Les packages HBase doivent Ãªtre tÃ©lÃ©chargÃ©s lors du spark-submit. Si cela Ã©choue:

1. VÃ©rifiez la connectivitÃ© rÃ©seau du conteneur
2. Utilisez `--repositories` si nÃ©cessaire
3. VÃ©rifiez que les versions sont compatibles

---

## ğŸ“š STRUCTURE DES FICHIERS

```
bigdata_project/
â”œâ”€â”€ benchmark_config.py              # Configuration centralisÃ©e
â”œâ”€â”€ benchmark_hbase.py               # Script benchmark HBase
â”œâ”€â”€ benchmark_parquet_complete.py    # Script benchmark Parquet
â”œâ”€â”€ generate_comparison.py           # Script de comparaison
â”œâ”€â”€ run_full_benchmark.sh            # Script principal
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ verify_services.sh           # VÃ©rification des services
â”‚   â”œâ”€â”€ prepare_hbase.sh             # PrÃ©paration HBase
â”‚   â”œâ”€â”€ upload_csv_to_hdfs.sh        # Upload CSV
â”‚   â””â”€â”€ create_hbase_catalog.py      # GÃ©nÃ©ration catalog JSON
â”œâ”€â”€ benchmark_results/               # RÃ©sultats (gÃ©nÃ©rÃ©)
â”‚   â”œâ”€â”€ comparison_results.csv
â”‚   â””â”€â”€ benchmark_report.md
â””â”€â”€ ANALYSE_PROJET.md                # Analyse initiale
```

---

## ğŸ¯ PROCHAINES Ã‰TAPES

AprÃ¨s avoir exÃ©cutÃ© le benchmark:

1. **Analyser les rÃ©sultats** dans le rapport markdown
2. **Comparer les performances** selon vos cas d'usage
3. **Ajuster la configuration** si nÃ©cessaire
4. **Tester avec un dataset plus volumineux** pour des rÃ©sultats plus reprÃ©sentatifs

---

## ğŸ“ SUPPORT

En cas de problÃ¨me:

1. Consultez les logs des conteneurs: `docker logs <container>`
2. VÃ©rifiez l'Ã©tat des services: `bash scripts/verify_services.sh`
3. Consultez `ANALYSE_PROJET.md` pour l'analyse initiale

---

**Bon benchmark! ğŸš€**

