# Projet Big Data ‚Äî Description d√©taill√©e

## R√©sum√© 
Ce d√©p√¥t est un projet de comparaison de formats de fichiers (CSV, Avro, ORC, Parquet) et d'architectures de stockage (Parquet/Hive vs HBase), avec des benchmarks d'ex√©cution r√©alis√©s via Spark et Hive, ainsi qu'un benchmark de mod√®les Spark ML. Le projet fournit des scripts pour d√©ployer une infrastructure Docker (HDFS, Hive Metastore, Spark, HBase), g√©n√©rer des donn√©es, ex√©cuter des benchmarks et collecter les r√©sultats.

## Objectifs üéØ
- Comparer les performances d'√©criture/lecture et la taille des formats de stockage courants.
- Comparer Parquet/Hive et HBase pour les patterns de lecture/√©criture cibl√©s.
- Benchmarker plusieurs mod√®les Spark ML sur le m√™me jeu de donn√©es.
- Fournir scripts reproductibles pour d√©ploiement et mesure.

## Architecture g√©n√©rale üèóÔ∏è
- Stockage des donn√©es: HDFS (dans le conteneur `namenode`/`datanode`).
- Moteurs: Apache Spark (master/worker) et Hive (metastore).
- Base NoSQL: HBase (master/regionserver) pour comparaison.
- Orchestration locale: `docker-compose.yml` pour lancer l'ensemble.

### Diagramme d'architecture üñºÔ∏è


![Sch√©ma d'architecture](docs/assets/architecture.png)

## Arborescence et r√¥le des principaux fichiers/folders üìÅ
-- `docker-compose.yml` : d√©finition des services Docker (NameNode, DataNode, Hive Metastore, Spark, HBase, PostgreSQL pour metastore, etc.).
- `config/` : fichiers de configuration pour Hadoop/Hive/HBase.
- `scripts/` : utilitaires pour pr√©parer l'environnement, g√©n√©rer des donn√©es et lancer les benchmarks.
  - `generate_data.py` : g√©n√©ration de jeux de donn√©es synth√©tiques.
  - `run_format_benchmark.sh`, `run_full_benchmark.sh`, `run_spark_ml.sh` : scripts d'automatisation.
  - `verify_services.sh` : tests rapides de disponibilit√© des services.
- `benchmarks/` : scripts PySpark pour effectuer les benchmarks.
  - `benchmark_formats.py` : bench formats (CSV, Avro, ORC, Parquet).
  - `benchmark_hbase.py` : bench lecture/√©criture HBase.
  - `benchmark_parquet_complete.py` : bench Parquet complet.
  - `read_csv_hive.py` : importer CSV et cr√©er table Hive.
  - `generate_comparison.py` : consolidation des r√©sultats.
- `spark_ml/` : scripts pour benchmarks Spark ML (`ml_benchmark.py`).
- `data/` : exemples de jeux de donn√©es (`sample_sales.csv`, `large_sales.csv`).
- `docs/` : documentation et tutoriels compl√©mentaires (`Tutoriel.md`, `Tutoriel_report.md`).
- `benchmark_results/`, `ml_results_csv/` : sorties/artefacts des benchmarks.

## D√©pendances et pr√©requis
- Docker & Docker Compose (version support√©e par les images utilis√©es)
- Sur la machine h√¥te: Git et (optionnel) `bash` pour lancer les scripts `.sh` depuis PowerShell.
- Les conteneurs contiennent Spark, Hadoop/HDFS, Hive, HBase, PostgreSQL.

## Quickstart (local, PowerShell sous Windows)
1. Lancer l'infrastructure:

```powershell
docker-compose up -d
```

2. V√©rifier les conteneurs:

```powershell
docker-compose ps
```

3. Cr√©er/charger les r√©pertoires HDFS et uploader le CSV de test:

```powershell
docker exec namenode hdfs dfs -mkdir -p /user/data
docker cp .\data\sample_sales.csv namenode:/tmp/sample_sales.csv
docker exec namenode hdfs dfs -put -f /tmp/sample_sales.csv /user/data/sample_sales.csv
```

4. Lancer un benchmark formats (exemple petit jeu de donn√©es):

```powershell
docker cp .\benchmarks\benchmark_formats.py spark-master-new:/benchmark_formats.py
docker exec spark-master-new /spark/bin/spark-submit --master spark://spark-master-new:7077 --packages org.apache.spark:spark-avro_2.12:3.1.1 /benchmark_formats.py --input-file "hdfs://namenode:8020/user/data/sample_sales.csv" --dataset-name "small"
```

Pour plus de commandes d'ex√©cution, voir `README.md` existant (guide pas-√†-pas d√©taill√© d'ex√©cution).

## Workflow recommand√©
- D√©marrer les services (`docker-compose up -d`)
- V√©rifier l'√©tat (`scripts/verify_services.sh`)
- G√©n√©rer les donn√©es si besoin (`scripts/generate_data.py`)
- Uploader les donn√©es dans HDFS
- Lancer les benchmarks (`scripts/run_format_benchmark.sh`, `scripts/run_full_benchmark.sh`)
- Lancer le benchmark ML via `scripts/run_spark_ml.sh`
- Collecter et analyser les r√©sultats dans `benchmark_results/` et `ml_results_csv/`

## O√π regarder en cas de probl√®me
- Logs Docker: `docker logs spark-master-new` ou `docker logs hbase-master`.
- V√©rifier configuration Hive/HBase dans `config/`.
- Scripts utilitaires: `scripts/diagnose_hbase.sh`, `scripts/show_metrics.py`.

Conclusion üßæ

En synth√®se, ce projet fournit une base exp√©rimentale compl√®te et reproductible pour analyser les compromis entre formats de donn√©es, architectures de stockage et performances de traitement dans un contexte Big Data.